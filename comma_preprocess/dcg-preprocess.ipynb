{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11906302,"sourceType":"datasetVersion","datasetId":7484651}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import h5py\nimport numpy as np\nfrom tqdm import tqdm\nfrom scipy import ndimage\nimport os\n\n# ðŸ“ Percorso ai file HDF5 caricati su Kaggle\nbase_path = \"/kaggle/input/hdf5-chunk1\"  # Assicurati che il nome del dataset sia giusto\n\n# ðŸ“ Directory di output scrivibile su Kaggle\noutput_dir = \"/kaggle/working\"\n\ndataset_types = ['train', 'val', 'test']\n\nfor dataset_type in dataset_types:\n    input_path = os.path.join(base_path, f\"gas_and_brake_{dataset_type}_comma_chunk_1_w_imgs.h5py\")\n    output_path = os.path.join(output_dir, f\"filtered_chunk1_{dataset_type}.hdf5\")\n\n    print(f\"ðŸ”„ Processing {dataset_type} from: {input_path}\")\n\n    if not os.path.exists(input_path):\n        print(f\"âŒ File not found: {input_path}\")\n        continue\n\n    with h5py.File(input_path, \"r\") as h5_file, h5py.File(output_path, \"w\") as h_out:\n        keys = list(h5_file.keys())\n\n        for key in tqdm(keys, desc=f\"Processing {dataset_type}\"):\n            group_in = h5_file[key]\n\n            #if 'desired_dist' not in group_in:\n             #   continue\n\n            #desired = np.array(group_in['desired_dist'][()])\n            #filtered = ndimage.median_filter(desired, size=12)\n\n            #if (filtered == 0).mean() > 0.2:\n             #   continue  # scarta campioni poco informativi\n\n            group_out = h_out.create_group(key)\n\n            for col in group_in.keys():\n                dt = np.float32 if col != 'image' else int\n                group_out.create_dataset(\n                    col,\n                    data=group_in[col],\n                    compression='gzip',\n                    compression_opts=6,\n                    chunks=True\n                )\n\n    print(f\"âœ… Salvato in: {output_path}\\n\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-22T13:37:14.558424Z","iopub.execute_input":"2025-05-22T13:37:14.558753Z","iopub.status.idle":"2025-05-22T13:54:58.325419Z","shell.execute_reply.started":"2025-05-22T13:37:14.558723Z","shell.execute_reply":"2025-05-22T13:54:58.323746Z"}},"outputs":[{"name":"stdout","text":"ðŸ”„ Processing train from: /kaggle/input/hdf5-chunk1/gas_and_brake_train_comma_chunk_1_w_imgs.hdf5\n","output_type":"stream"},{"name":"stderr","text":"Processing train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [13:40<00:00, 11.72s/it]\n","output_type":"stream"},{"name":"stdout","text":"âœ… Salvato in: /kaggle/working/filtered_chunk1_train.hdf5\n\nðŸ”„ Processing val from: /kaggle/input/hdf5-chunk1/gas_and_brake_val_comma_chunk_1_w_imgs.hdf5\n","output_type":"stream"},{"name":"stderr","text":"Processing val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [02:16<00:00, 11.36s/it]\n","output_type":"stream"},{"name":"stdout","text":"âœ… Salvato in: /kaggle/working/filtered_chunk1_val.hdf5\n\nðŸ”„ Processing test from: /kaggle/input/hdf5-chunk1/gas_and_brake_test_comma_chunk_1_w_imgs.hdf5\n","output_type":"stream"},{"name":"stderr","text":"Processing test: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [01:45<00:00, 11.75s/it]","output_type":"stream"},{"name":"stdout","text":"âœ… Salvato in: /kaggle/working/filtered_chunk1_test.hdf5\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":1}]}