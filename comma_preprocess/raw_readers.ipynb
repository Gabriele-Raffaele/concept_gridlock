{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_segment = '../Example_1/b0c9d2329ad1606b|2018-08-02--08-34-47/40/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall lru-dict -y\n",
    "!ARCHFLAGS=\"-arch arm64\" pip install lru-dict --compile --no-cache-dir\n",
    "!set -x PYCURL_SSL_LIBRARY openssl\n",
    "!export PYCURL_SSL_LIBRARY=openssl\n",
    "!export LDFLAGS=-L/usr/local/opt/openssl/lib\n",
    "!export CPPFLAGS=-I/usr/local/opt/openssl/include\n",
    "!ARCHFLAGS=\"-arch arm64\" pip install pycurl --no-cache-dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!arch -arm64 pip install pycurl --compile --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ARCHFLAGS=\"-arch arm64\" pip install pycapnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!brew uninstall openssl\n",
    "!brew install https://github.com/tebelorg/Tump/releases/download/v1.0.0/openssl.rb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('64bit', '')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import platform\n",
    "platform.architecture()\n",
    "sys.path.append(\"../openpilot\")\n",
    "from tools.lib.logreader import LogReader\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tools.lib.framereader import FrameReader\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example_segment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c647841a7234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_segment\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'raw_log.bz2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# make list of logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'example_segment' is not defined"
     ]
    }
   ],
   "source": [
    "lr = LogReader(example_segment + 'raw_log.bz2')\n",
    "# make list of logs\n",
    "logs = list(lr)\n",
    "[l.which() for l in logs[:50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e4e9c0571c8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrolsState\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liveTracks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'logs' is not defined"
     ]
    }
   ],
   "source": [
    "[l.controlsState for l in logs if l.which() == 'liveTracks'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6843dfbecf88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# we print the types of the first 50 logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# we can plot the speed of the car by getting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# all the carState logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'logs' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# we print the types of the first 50 logs\n",
    "wh = [l.which() for l in logs[:50]]\n",
    "\n",
    "# we can plot the speed of the car by getting\n",
    "# all the carState logs\n",
    "'''figsize(12,12);\n",
    "plot([l.carState.vEgo for l in logs if l.which() == 'carState'], linewidth=3);\n",
    "title('Car speed from raw logs (m/s)', fontsize=25);\n",
    "xlabel('boot time (s)', fontsize=18);\n",
    "ylabel('speed (m/s)', fontsize=18);'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example_segment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-40bdd41e7cb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mframe_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_segment\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'video.hevc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#figsize(12,12)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#imshow(fr.get(frame_index, pix_fmt='rgb24')[0]);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'example_segment' is not defined"
     ]
    }
   ],
   "source": [
    "# We can extract frames from the video with framereader\n",
    "# from openpilot tools, we look at frame 600\n",
    "frame_index = 600\n",
    "\n",
    "fr = FrameReader(example_segment + 'video.hevc')\n",
    "#figsize(12,12)\n",
    "#imshow(fr.get(frame_index, pix_fmt='rgb24')[0]);\n",
    "#title('Frame 600 extracted from video with FrameReader', fontsize=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(p):\n",
    "    frame_reader = FrameReader(p+'/video.hevc')\n",
    "    logs = list(LogReader(p + '/raw_log.bz2'))\n",
    "\n",
    "    angle = np.array([l.carState.steeringAngleDeg for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    time = np.array([l.logMonoTime for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    vEgo = np.array([l.carState.vEgo for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    gas = np.array([l.carState.gas for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    brake = np.array([l.carState.brake for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    gps_times = np.load(p + '/global_pose/frame_gps_times')\n",
    "    times = np.load(p + '/global_pose/frame_times')\n",
    "    gas = np.array([l.carState.gas for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    gaspressed = np.array([l.carState.gasPressed for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    brake = np.array([l.carState.brake for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    brake_pressed = np.array([l.carState.brakePressed for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "\n",
    "    enabled = np.array([l.carState.cruiseState.enabled for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    speed = np.array([l.carState.cruiseState.speed for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    speedOffset = np.array([l.carState.cruiseState.speedOffset for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    standstill = np.array([l.carState.cruiseState.standstill for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    nonAdaptive = np.array([l.carState.cruiseState.nonAdaptive for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    speedCluster = np.array([l.carState.cruiseState.speedCluster for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    \n",
    "    leftBlinker = np.array([l.carState.leftBlinker for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    rightBlinker = np.array([l.carState.rightBlinker for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
    "    #print(frame_reader.frame_count, gps_times.shape, times.shape)\n",
    "    #print([l.carState for l in logs if l.which() == \"carState\"][0])\n",
    "    #print([l.radarState for l in logs if l.which() == \"radarState\"][0])\n",
    "\n",
    "    dist = np.array([l.radarState.leadOne.dRel for l in logs if l.which() == \"radarState\"])[1::5]\n",
    "    if ((vEgo == 0).mean() > 0.2) or ((dist == 0).mean() > 0.2) or len(dist) <=230:\n",
    "        return None\n",
    "    images = []\n",
    "    l = list(range(frame_reader.frame_count))\n",
    "    if len(l) > 245:\n",
    "        l = l[1::5]\n",
    "    for idx in list(range(frame_reader.frame_count))[1::5]:\n",
    "        image = np.array(frame_reader.get(idx, pix_fmt='rgb24')[0], dtype=np.float64)\n",
    "        image = cv2.resize(image, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "        images.append(image)\n",
    "    steady_state = ~gaspressed & ~brake_pressed & ~leftBlinker & ~rightBlinker\n",
    "    last_idx = 0\n",
    "    desired_gap = np.zeros(steady_state.shape)\n",
    "\n",
    "    for i in range(len(steady_state)-1):\n",
    "        if steady_state[i] == True:\n",
    "            desired_gap[last_idx:i] = int(dist[i])\n",
    "            last_idx = i\n",
    "\n",
    "    sample = {\n",
    "        'image': images,\n",
    "        \"CruiseStateenabled\": enabled,#[1::5],\n",
    "        \"CruiseStatespeed\": speed,#[1::5],\n",
    "        \"CruiseStatespeedOffset\": speedOffset,#1::5],\n",
    "        \"CruiseStatestandstill\": standstill,#[1::5],\n",
    "        \"CruiseStatenonAdaptive\": nonAdaptive,#[1::5],\n",
    "        \"CruiseStatespeedCluster\": speedCluster,#[1::5],\n",
    "        'leftBlinker': leftBlinker,#[1::5],\n",
    "        'rightBlinker': rightBlinker,#[1::5],\n",
    "        \"gas\": gas,#[1::5],\n",
    "        \"gaspressed\": gaspressed,#[1::5],\n",
    "        \"brake\": brake,#[1::5],\n",
    "        \"brakepressed\": brake_pressed,#[1::5],\n",
    "        'angle': angle,#[1::5],\n",
    "        'time': time,#[1::5],\n",
    "        'gas': gas,#[1::5],\n",
    "        'vEgo': vEgo,#[1::5],\n",
    "        'brake': brake,#[1::5],\n",
    "        'dist': dist,#[1::5],\n",
    "        'desired_dist': desired_gap,\n",
    "        } \n",
    "    return sample if not ((desired_gap == 0).mean() > 0.2) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_h5py(i, sample, h):\n",
    "    group = h.create_group(str(i))\n",
    "    for col in sample.keys():\n",
    "            dt = np.float32 if col != 'image' else int#\n",
    "            dataset_name = col #groups are divided by '/'\n",
    "            a = list(sample[col])\n",
    "            group.create_dataset(dataset_name, data = np.asarray(a, dtype=dt),\n",
    "                    #compression_opts=9,\n",
    "                    #chunks=(164, 20, 20, 3),\n",
    "                    compression='lzf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"train\"\n",
    "main_dir='/Users/jessicaechterhoff/Dropbox/UCSD_2022_2023/Research/toyota/commaai/comma2k19/comma2k19/Chunk_1/'\n",
    "hdf5_filename = \"gas_and_brake_train_comma_chunk_1_w_imgs.hfd5\"\n",
    "h_train = h5py.File(hdf5_filename, 'w')\n",
    "hdf5_filename = \"gas_and_brake_val_comma_chunk_1_w_imgs.hfd5\"\n",
    "h_val = h5py.File(hdf5_filename, 'w')\n",
    "hdf5_filename = \"gas_and_brake_test_comma_chunk_1_w_imgs.hfd5\"\n",
    "h_test = h5py.File(hdf5_filename, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [28:05, 73.28s/it] \n"
     ]
    }
   ],
   "source": [
    "for j, drive_sequence_path in tqdm(enumerate(os.listdir(main_dir))):\n",
    "    if '.DS_Store ' in drive_sequence_path or not os.path.isdir(main_dir+\"/\"+drive_sequence_path): continue\n",
    "    min_sequence_paths = os.listdir(main_dir+\"/\"+drive_sequence_path)\n",
    "    if len(min_sequence_paths) < 3: continue\n",
    "    min_sequence_path_test = main_dir+\"/\"+drive_sequence_path+\"/\"+min_sequence_paths[-2]\n",
    "    min_sequence_paths_val = main_dir+\"/\"+drive_sequence_path+\"/\"+min_sequence_paths[-1]\n",
    "    sample = get_sample(min_sequence_path_test)\n",
    "    if sample != None:\n",
    "        save_h5py(f\"{drive_sequence_path}\", sample, h_test)\n",
    "    sample = get_sample(min_sequence_paths_val)\n",
    "\n",
    "    if sample != None:\n",
    "        save_h5py(f\"{drive_sequence_path}\", sample, h_val)\n",
    "    for i, min_sequence in enumerate(min_sequence_paths[:-2]):\n",
    "        if '.DS_Store ' in min_sequence or not os.path.isdir(main_dir+\"/\"+drive_sequence_path+'/'+min_sequence): continue\n",
    "        p = main_dir+\"/\"+drive_sequence_path+\"/\"+min_sequence\n",
    "        sample = get_sample(p)\n",
    "        if sample != None:\n",
    "            save_h5py(f\"{drive_sequence_path}_{min_sequence}\", sample, h_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_test.close()\n",
    "h_train.close()\n",
    "h_val.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6902778\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('gas_and_brake_train_comma_chunk_1_w_imgs.hfd5', \"r\") as f:\n",
    "    # Print all root level object names (aka keys) \n",
    "    # these can be group or dataset names \n",
    "    #     # get first object name/key; may or may NOT be a group\n",
    "    all_group_key = list(f.keys())\n",
    "    allcc = []\n",
    "    for a_group_key in all_group_key:\n",
    "    \n",
    "        data = list(f[a_group_key])\n",
    "        # preferred methods to get dataset values:\n",
    "        ds_obj = f[a_group_key]      # returns as a h5py dataset object\n",
    "        ds_arr = f[a_group_key]['dist'][()]\n",
    "        ds_arr = f[a_group_key]['CruiseStateenabled'][()].mean()\n",
    "        allcc.append(ds_arr)\n",
    "    print(np.array(allcc).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6369225\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('gas_and_brake_train_comma_chunk_3_w_imgs.hfd5', \"r\") as f:\n",
    "    # Print all root level object names (aka keys) \n",
    "    # these can be group or dataset names \n",
    "    #     # get first object name/key; may or may NOT be a group\n",
    "    all_group_key = list(f.keys())\n",
    "    allcc = []\n",
    "    for a_group_key in all_group_key:\n",
    "    \n",
    "        data = list(f[a_group_key])\n",
    "        # preferred methods to get dataset values:\n",
    "        ds_obj = f[a_group_key]      # returns as a h5py dataset object\n",
    "        ds_arr = f[a_group_key]['dist'][()]\n",
    "        ds_arr = f[a_group_key]['CruiseStateenabled'][()].mean()\n",
    "        allcc.append(ds_arr)\n",
    "    print(np.array(allcc).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8325231\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('gas_and_brake_train_comma_chunk_2_w_imgs.hfd5', \"r\") as f:\n",
    "    # Print all root level object names (aka keys) \n",
    "    # these can be group or dataset names \n",
    "    #     # get first object name/key; may or may NOT be a group\n",
    "    all_group_key = list(f.keys())\n",
    "    allcc = []\n",
    "    for a_group_key in all_group_key:\n",
    "    \n",
    "        data = list(f[a_group_key])\n",
    "        # preferred methods to get dataset values:\n",
    "        ds_obj = f[a_group_key]      # returns as a h5py dataset object\n",
    "        ds_arr = f[a_group_key]['dist'][()]\n",
    "        ds_arr = f[a_group_key]['CruiseStateenabled'][()].mean()\n",
    "        allcc.append(ds_arr)\n",
    "    print(np.array(allcc).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return {\n",
    "            key: torch.from_numpy(value) for key, value in sample.items()\n",
    "        }\n",
    "\n",
    "\n",
    "class CommaDataset(Dataset):\n",
    "\n",
    "    def get_sample(self, main_dir, p):\n",
    "                frame_reader = FrameReader(p + 'video.hevc')\n",
    "                gps_times = np.load(main_dir + 'global_pose/frame_gps_times')\n",
    "                orientations = np.load(main_dir + 'global_pose/frame_orientations')\n",
    "                positions = np.load(main_dir + 'global_pose/frame_positions')\n",
    "                times = np.load(main_dir + 'global_pose/frame_times')\n",
    "                velocities = np.load(main_dir + 'global_pose/frame_velocities')\n",
    "\n",
    "                lr = LogReader(main_dir + 'raw_log.bz2')\n",
    "                logs = list(lr)\n",
    "\n",
    "                angle = [l.carState.steeringAngleDeg for l in logs if l.which() == 'carState']\n",
    "                time = [l.logMonoTime for l in logs if l.which() == 'carState']\n",
    "                vEgo = [l.carState.vEgo for l in logs if l.which() == 'carState']\n",
    "                gas = [l.carState.gas for l in logs if l.which() == 'carState']\n",
    "                brake = [l.carState.brake for l in logs if l.which() == 'carState']\n",
    "                dist = [l.radarState.leadOne.dRel for l in logs if l.which() == \"radarState\"]\n",
    "\n",
    "                angle = np.array(angle)[1::5]\n",
    "                time = np.array(time)[1::5]\n",
    "                vEgo = np.array(vEgo)[1::5]\n",
    "                gas = np.array(gas)[1::5]\n",
    "                brake = np.array(brake)[1::5]\n",
    "                dist = np.array(dist)[1::5]\n",
    "                images = []\n",
    "                for idx in range(frame_reader.frame_count):\n",
    "                    image = np.array(frame_reader.get(idx, pix_fmt='rgb24')[0], dtype=np.float64)\n",
    "                    image = cv2.resize(image, 224)\n",
    "                    images.append(image)\n",
    "                sample = {\n",
    "                'image': images,\n",
    "                'angle': angle,\n",
    "                'time': time,\n",
    "                'gas': gas,\n",
    "                'vEgo': vEgo,\n",
    "                'brake': brake,\n",
    "                'dist': dist,\n",
    "                }\n",
    "                return sample\n",
    "\n",
    "    def __init__(self, main_dir, transform=None, dataset_type='train'):\n",
    "        self.main_dir = main_dir\n",
    "        self.dataset_type = dataset_type\n",
    "        self.train_sequences = []\n",
    "        self.val_sequences = []\n",
    "        self.test_sequences = []\n",
    "        for drive_sequence_path in os.listdir(main_dir):\n",
    "            min_sequence_paths = os.listdir(main_dir+\"/\"+drive_sequence_path)\n",
    "            min_sequence_path_test = min_sequence_paths[-2]\n",
    "            min_sequence_paths_val = min_sequence_paths[-1]\n",
    "            sample = self.get_sample(main_dir, min_sequence_path_test)\n",
    "            self.test_sequences.append(sample)\n",
    "            sample = self.get_sample(main_dir, min_sequence_paths_val)\n",
    "            self.val_sequences.append(sample)\n",
    "            for min_sequence in min_sequence_paths[:-2]:\n",
    "                p = main_dir+\"/\"+drive_sequence_path+\"/\"+min_sequence\n",
    "                sample = self.get_sample(main_dir, p)\n",
    "                self.train_sequences.append(sample)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.velocities)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.dataset_type == \"train\":\n",
    "            return self.train_sequences[idx]\n",
    "        if self.dataset_type == \"val\":\n",
    "            return self.train_sequences[idx]\n",
    "        if self.dataset_type == \"test\":\n",
    "            return self.train_sequences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_segment = '../Example_1/b0c9d2329ad1606b|2018-08-02--08-34-47/40/'\n",
    "\n",
    "comma_dataset = CommaDataset(main_dir=example_segment, transform=transforms.Compose([\n",
    "        ToTensor(), \n",
    "        #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))#,\n",
    "        #transforms.Resize(224)\n",
    "    ]))\n",
    "comma_dataloader = DataLoader(comma_dataset, batch_size=240, shuffle=False, num_workers=0)\n",
    "\n",
    "#sample = comma_dataset[frame_idx]\n",
    "sample = next(iter(comma_dataloader))\n",
    "#image = sample['image'][0].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sample['image'])):\n",
    "    if i % 10 != 0:\n",
    "        continue\n",
    "    imshow(np.array(sample['image'][i]).astype(int));\n",
    "    angle = round(sample['angle'][i].item(), 4)\n",
    "    brake = round(sample['brake'][i].item(), 4)\n",
    "    dist = round(sample['dist'][i].item(), 4)\n",
    "    vEgo = round(sample['vEgo'][i].item(), 4)\n",
    "    gas = round(sample['gas'][i].item(), 4)\n",
    "    title(f'angle {angle}, brake {brake}, dist {dist}, vEgo {vEgo}, gas {gas}', fontsize=15);\n",
    "    plt.savefig(f'{i}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "sys.path.append(\"../openpilot\")\n",
    "from tools.lib.logreader import LogReader\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from tools.lib.framereader import FrameReader\n",
    "import h5py\n",
    "\n",
    "def get_sample(main_dir, p):\n",
    "                frame_reader = FrameReader(p+'/video.hevc')\n",
    "\n",
    "                lr = LogReader(p + '/raw_log.bz2')\n",
    "                logs = list(lr)\n",
    "\n",
    "                angle = [l.carState.steeringAngleDeg for l in logs if l.which() == 'carState']\n",
    "                time = [l.logMonoTime for l in logs if l.which() == 'carState']\n",
    "                vEgo = [l.carState.vEgo for l in logs if l.which() == 'carState']\n",
    "                gas = [l.carState.gas for l in logs if l.which() == 'carState']\n",
    "                brake = [l.carState.brake for l in logs if l.which() == 'carState']\n",
    "                dist = [l.radarState.leadOne.dRel for l in logs if l.which() == \"radarState\"]\n",
    "                angle = np.array(angle)[1::5][1::5]\n",
    "                time = np.array(time)[1::5][1::5]\n",
    "                vEgo = np.array(vEgo)[1::5][1::5]\n",
    "                gas = np.array(gas)[1::5][1::5]\n",
    "                brake = np.array(brake)[1::5][1::5]\n",
    "                dist = np.array(dist)[1::5]\n",
    "                assert((dist < 0).sum() == 0)\n",
    "                \n",
    "                images = []\n",
    "                for idx in range(frame_reader.frame_count):\n",
    "                    image = np.array(frame_reader.get(idx, pix_fmt='rgb24')[0], dtype=np.float64)\n",
    "                    image = cv2.resize(image, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "                    images.append(image)\n",
    "                sample = {\n",
    "                'image': images,\n",
    "                'angle': angle,\n",
    "                'time': time,\n",
    "                'gas': gas,\n",
    "                'vEgo': vEgo,\n",
    "                'brake': brake,\n",
    "                'dist': dist,\n",
    "                }\n",
    "                images = images[1::5]\n",
    "                print(len(images))\n",
    "                assert(len(angle) ==len(time) == len(vEgo) ==len(gas)== len(brake) ==len(dist))\n",
    "                return sample\n",
    "\n",
    "dataset_type = \"train\"\n",
    "main_dir='/Users/jessicaechterhoff/Dropbox/UCSD_2022_2023/Research/toyota/commaai/comma2k19/comma2k19/Chunk_1/'\n",
    "train_sequences = []\n",
    "#val_sequences = []\n",
    "#test_sequences = []\n",
    "j = 0\n",
    "for ij, drive_sequence_path in enumerate(os.listdir(main_dir)):\n",
    "    print(drive_sequence_path)\n",
    "    if ij <10: continue\n",
    "    if ij >=20: break\n",
    "    if '.DS_Store ' in drive_sequence_path or not os.path.isdir(main_dir+\"/\"+drive_sequence_path): continue\n",
    "\n",
    "    min_sequence_paths = os.listdir(main_dir+\"/\"+drive_sequence_path)\n",
    "    '''min_sequence_path_test = main_dir+\"/\"+drive_sequence_path+\"/\"+min_sequence_paths[-2]\n",
    "    min_sequence_paths_val = main_dir+\"/\"+drive_sequence_path+\"/\"+min_sequence_paths[-1]\n",
    "    print(min_sequence_path_test)\n",
    "    sample = get_sample(main_dir, min_sequence_path_test)\n",
    "    test_sequences.append(sample)\n",
    "    sample = get_sample(main_dir, min_sequence_paths_val)\n",
    "    val_sequences.append(sample)'''\n",
    "    for min_sequence in min_sequence_paths[:-2]:\n",
    "        j +=1\n",
    "        if '.DS_Store ' in min_sequence or not os.path.isdir(main_dir+\"/\"+drive_sequence_path+'/'+min_sequence): continue\n",
    "        p = main_dir+\"/\"+drive_sequence_path+\"/\"+min_sequence\n",
    "        sample = get_sample(main_dir, p)\n",
    "        train_sequences.append(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(name, sequence):\n",
    "    hdf5_filename = f\"{name}_comma_2.hfd5\"\n",
    "    h = h5py.File(hdf5_filename, 'w')\n",
    "    index = 0\n",
    "    for i, entry in enumerate(sequence):\n",
    "        groupname = str(i)\n",
    "        group = h.create_group(groupname)\n",
    "        \n",
    "        for col in entry.keys():\n",
    "            dt = np.float32 if col != 'image' else int#\n",
    "            dataset_name = col #groups are divided by '/'\n",
    "            a = list(entry[col])\n",
    "            group.create_dataset(dataset_name, data = np.asarray(a, dtype=dt), compression='lzf')\n",
    "        index = index +1\n",
    "    h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\"train\", train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\"train\", train_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6ba58c45dab89b2514588d38e9290524be89266c2f7a797ba911e1e9b00c0381"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
