{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabriele-Raffaele/concept_gridlock/blob/master/DCG_convert_chunk1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Raw Readers"
      ],
      "metadata": {
        "id": "FdwcO26eLp08"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caPmSFqoOgd7",
        "outputId": "30ed196c-0fbb-4175-8d02-d78cb0e254d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'openpilot' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Gabriele-Raffaele/openpilot.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QvmZWiw2VjN2",
        "outputId": "3e7c0cb1-2d9f-4e2b-96a4-c69478a3270d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajQ6pY2DbLdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6ee18d-1221-470e-9c53-7bda4aa2effb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycapnp in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: smbus2 in /usr/local/lib/python3.11/dist-packages (0.5.0)\n",
            "Requirement already satisfied: lru-dict in /usr/local/lib/python3.11/dist-packages (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pycapnp\n",
        "!pip install smbus2\n",
        "!pip install lru-dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAna3ipRVtbb",
        "outputId": "0f566b91-8fb6-4577-f3d6-856d1b88494c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "position: /content\n",
            "CEREAL_PATH: /content/openpilot/cereal\n"
          ]
        }
      ],
      "source": [
        "from __future__ import print_function\n",
        "import os\n",
        "import numpy as np\n",
        "import sys\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "import platform\n",
        "platform.architecture()\n",
        "sys.path.append(\"/content/openpilot\")\n",
        "from tools.lib.logreader import LogReader\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from tools.lib.framereader import FrameReader\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBrZDaWVcs7k",
        "outputId": "1f03695f-8ca5-4d85-d2ca-5e5ac907fe8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'comma2k19'...\n",
            "remote: Enumerating objects: 152, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 152 (delta 20), reused 15 (delta 15), pack-reused 119 (from 1)\u001b[K\n",
            "Receiving objects: 100% (152/152), 56.17 MiB | 19.45 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/commaai/comma2k19.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZoT_W42dKxJ",
        "outputId": "0bbf9f57-91d1-49f9-e65a-8bc98fd0f90e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sensorEventsDEPRECATED',\n",
              " 'controlsState',\n",
              " 'sendcan',\n",
              " 'carState',\n",
              " 'carControl',\n",
              " 'logMessage',\n",
              " 'can',\n",
              " 'longitudinalPlan',\n",
              " 'can',\n",
              " 'sendcan',\n",
              " 'sensorEventsDEPRECATED',\n",
              " 'sensorEventsDEPRECATED',\n",
              " 'carState',\n",
              " 'controlsState',\n",
              " 'carControl',\n",
              " 'logMessage',\n",
              " 'logMessage',\n",
              " 'logMessage',\n",
              " 'can',\n",
              " 'roadEncodeIdx',\n",
              " 'roadEncodeIdx',\n",
              " 'longitudinalPlan',\n",
              " 'controlsState',\n",
              " 'sendcan',\n",
              " 'carState',\n",
              " 'carControl',\n",
              " 'sensorEventsDEPRECATED',\n",
              " 'can',\n",
              " 'logMessage',\n",
              " 'logMessage',\n",
              " 'radarState',\n",
              " 'liveTracksDEPRECATED',\n",
              " 'can',\n",
              " 'sensorEventsDEPRECATED',\n",
              " 'liveLongitudinalMpcDEPRECATED',\n",
              " 'can',\n",
              " 'longitudinalPlan',\n",
              " 'liveLongitudinalMpcDEPRECATED',\n",
              " 'sendcan',\n",
              " 'sensorEventsDEPRECATED',\n",
              " 'sensorEventsDEPRECATED',\n",
              " 'sensorEventsDEPRECATED',\n",
              " 'controlsState',\n",
              " 'carState',\n",
              " 'carControl',\n",
              " 'can',\n",
              " 'roadCameraState',\n",
              " 'sensorEventsDEPRECATED',\n",
              " 'sensorEventsDEPRECATED',\n",
              " 'sensorEventsDEPRECATED']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "example_segment = '/content/comma2k19/Example_1/b0c9d2329ad1606b|2018-08-02--08-34-47/40/'\n",
        "lr = LogReader(example_segment + 'raw_log.bz2')\n",
        "# make list of logs\n",
        "logs = list(lr)\n",
        "[l.which() for l in logs[:50]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbizo5kMC8YU"
      },
      "outputs": [],
      "source": [
        "# We can extract frames from the video with framereader\n",
        "# from openpilot tools, we look at frame 600\n",
        "frame_index = 600\n",
        "\n",
        "fr = FrameReader(example_segment + 'video.hevc')\n",
        "#figsize(12,12)\n",
        "#imshow(fr.get(frame_index, pix_fmt='rgb24')[0]);\n",
        "#title('Frame 600 extracted from video with FrameReader', fontsize=25);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sGheqnW3C8V4"
      },
      "outputs": [],
      "source": [
        "def get_sample(p):\n",
        "    frame_reader = FrameReader(p+'/video.hevc')\n",
        "    logs = list(LogReader(p + '/raw_log.bz2'))\n",
        "\n",
        "    angle = np.array([l.carState.steeringAngleDeg for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "    time = np.array([l.logMonoTime for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "    vEgo = np.array([l.carState.vEgo for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "    gas = np.array([l.carState.gas for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "    brake = np.array([l.carState.brake for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "    gps_times = np.load(p + '/global_pose/frame_gps_times')\n",
        "    times = np.load(p + '/global_pose/frame_times')\n",
        "    gas = np.array([l.carState.gas for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "    gaspressed = np.array([l.carState.gasPressed for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "    brake = np.array([l.carState.brake for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "    brake_pressed = np.array([l.carState.brakePressed for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "\n",
        "    enabled = np.array([l.carState.cruiseState.enabled for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "    speed = np.array([l.carState.cruiseState.speed for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "    speedOffset = np.array([l.carState.cruiseState.speedOffset for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "    standstill = np.array([l.carState.cruiseState.standstill for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "    nonAdaptive = np.array([l.carState.cruiseState.nonAdaptive for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "    speedCluster = np.array([l.carState.cruiseState.speedCluster for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "\n",
        "    leftBlinker = np.array([l.carState.leftBlinker for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "    rightBlinker = np.array([l.carState.rightBlinker for l in logs if l.which() == 'carState'])[1::5][1::5]\n",
        "    #print(frame_reader.frame_count, gps_times.shape, times.shape)\n",
        "    #print([l.carState for l in logs if l.which() == \"carState\"][0])\n",
        "    #print([l.radarState for l in logs if l.which() == \"radarState\"][0])\n",
        "\n",
        "    dist = np.array([l.radarState.leadOne.dRel for l in logs if l.which() == \"radarState\"])[1::5]\n",
        "    if ((vEgo == 0).mean() > 0.2) or ((dist == 0).mean() > 0.2) or len(dist) <=230:\n",
        "        return None\n",
        "    images = []\n",
        "    l = list(range(frame_reader.frame_count))\n",
        "    if len(l) > 245:\n",
        "        l = l[1::5]\n",
        "    for idx in list(range(frame_reader.frame_count))[1::5]:\n",
        "        image = np.array(frame_reader.get(idx, pix_fmt='rgb24')[0], dtype=np.float64)\n",
        "        image = cv2.resize(image, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n",
        "        images.append(image)\n",
        "    steady_state = ~gaspressed & ~brake_pressed & ~leftBlinker & ~rightBlinker\n",
        "    last_idx = 0\n",
        "    desired_gap = np.zeros(steady_state.shape)\n",
        "\n",
        "    for i in range(len(steady_state)-1):\n",
        "        if steady_state[i] == True:\n",
        "            desired_gap[last_idx:i] = int(dist[i])\n",
        "            last_idx = i\n",
        "\n",
        "    sample = {\n",
        "        'image': images,\n",
        "        \"CruiseStateenabled\": enabled,\n",
        "        \"CruiseStatespeed\": speed,\n",
        "        \"CruiseStatespeedOffset\": speedOffset,\n",
        "        \"CruiseStatestandstill\": standstill,\n",
        "        \"CruiseStatenonAdaptive\": nonAdaptive,\n",
        "        \"CruiseStatespeedCluster\": speedCluster,\n",
        "        'leftBlinker': leftBlinker,\n",
        "        'rightBlinker': rightBlinker,\n",
        "        \"gas\": gas,\n",
        "        \"gaspressed\": gaspressed,\n",
        "        \"brake\": brake,\n",
        "        \"brakepressed\": brake_pressed,\n",
        "        'angle': angle,\n",
        "        'time': time,\n",
        "        'gas': gas,\n",
        "        'vEgo': vEgo,\n",
        "        'brake': brake,\n",
        "        'dist': dist,\n",
        "        'desired_dist': desired_gap,\n",
        "        }\n",
        "    return sample if not ((desired_gap == 0).mean() > 0.2) else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8iCEQ_RC8TP"
      },
      "outputs": [],
      "source": [
        "def save_h5py(i, sample, h):\n",
        "    group = h.create_group(str(i))\n",
        "    for col in sample.keys():\n",
        "            dt = np.float32 if col != 'image' else int#\n",
        "            dataset_name = col #groups are divided by '/'\n",
        "            a = list(sample[col])\n",
        "            group.create_dataset(dataset_name, data = np.asarray(a, dtype=dt),\n",
        "                    #compression_opts=9,\n",
        "                    #chunks=(164, 20, 20, 3),\n",
        "                    compression='lzf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E770l3VajnQb",
        "outputId": "7f15b08d-6f3b-440c-d91a-c8ee04d1b158"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/dataset'\n",
            "/content\n",
            "--2025-05-21 13:34:24--  https://huggingface.co/datasets/commaai/comma2k19/resolve/main/Chunk_1.zip?download=true\n",
            "Resolving huggingface.co (huggingface.co)... 3.163.189.90, 3.163.189.114, 3.163.189.74, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.163.189.90|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/07/db/07dbdc4afc2545f4890b9e714253fb2cd7bce5471348d923dd7e55a3e710884f/b7f18b77ca5980e36d536344995bcfaffd4cbe6b84fe43ca443ea20c26547e30?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27Chunk_1.zip%3B+filename%3D%22Chunk_1.zip%22%3B&response-content-type=application%2Fzip&Expires=1747838064&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NzgzODA2NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8wNy9kYi8wN2RiZGM0YWZjMjU0NWY0ODkwYjllNzE0MjUzZmIyY2Q3YmNlNTQ3MTM0OGQ5MjNkZDdlNTVhM2U3MTA4ODRmL2I3ZjE4Yjc3Y2E1OTgwZTM2ZDUzNjM0NDk5NWJjZmFmZmQ0Y2JlNmI4NGZlNDNjYTQ0M2VhMjBjMjY1NDdlMzA%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=BzdoqRWN1rlJqF6FLGAryMRkZ2mALEhcfzlfycWAETHvc-KJ0EUDATUoEakm5kadEB1hJn8KI1sJGuL-FmmtnKjoU2C2fvIX1s3WIKkzTxUMqRlvnYS37IvO3woclfDkNUAvO%7EtFHy-yGzmBIvGRiWYRzLWBshICA7KEHbNnbNPNL905-68Nr9C-2omY7zvWYfnzk6EglaewOnKqg3okcmvE9A%7EDLit3nJ18XC8FHh5FpwxnaBt6mn4enucZXvb1VWAKz5OJSkqWr4ARYdVkx69ggJygV2af6phe8-wS%7EAmbH8UUNYuBj6mBMB4o%7EjazBrh9ROKKu8aySBGU6xa2vw__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-05-21 13:34:25--  https://cdn-lfs.hf.co/repos/07/db/07dbdc4afc2545f4890b9e714253fb2cd7bce5471348d923dd7e55a3e710884f/b7f18b77ca5980e36d536344995bcfaffd4cbe6b84fe43ca443ea20c26547e30?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27Chunk_1.zip%3B+filename%3D%22Chunk_1.zip%22%3B&response-content-type=application%2Fzip&Expires=1747838064&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NzgzODA2NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8wNy9kYi8wN2RiZGM0YWZjMjU0NWY0ODkwYjllNzE0MjUzZmIyY2Q3YmNlNTQ3MTM0OGQ5MjNkZDdlNTVhM2U3MTA4ODRmL2I3ZjE4Yjc3Y2E1OTgwZTM2ZDUzNjM0NDk5NWJjZmFmZmQ0Y2JlNmI4NGZlNDNjYTQ0M2VhMjBjMjY1NDdlMzA%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=BzdoqRWN1rlJqF6FLGAryMRkZ2mALEhcfzlfycWAETHvc-KJ0EUDATUoEakm5kadEB1hJn8KI1sJGuL-FmmtnKjoU2C2fvIX1s3WIKkzTxUMqRlvnYS37IvO3woclfDkNUAvO%7EtFHy-yGzmBIvGRiWYRzLWBshICA7KEHbNnbNPNL905-68Nr9C-2omY7zvWYfnzk6EglaewOnKqg3okcmvE9A%7EDLit3nJ18XC8FHh5FpwxnaBt6mn4enucZXvb1VWAKz5OJSkqWr4ARYdVkx69ggJygV2af6phe8-wS%7EAmbH8UUNYuBj6mBMB4o%7EjazBrh9ROKKu8aySBGU6xa2vw__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.172.170.29, 18.172.170.5, 18.172.170.108, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.172.170.29|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8731252405 (8.1G) [application/zip]\n",
            "Saving to: ‘Chunk_1.zip?download=true’\n",
            "\n",
            "Chunk_1.zip?downloa 100%[===================>]   8.13G  78.7MB/s    in 1m 47s  \n",
            "\n",
            "2025-05-21 13:36:12 (77.8 MB/s) - ‘Chunk_1.zip?download=true’ saved [8731252405/8731252405]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Vai nella cartella\n",
        "%cd /content/dataset\n",
        "\n",
        "# Scarica il primo chunk (~9GB)\n",
        "!wget https://huggingface.co/datasets/commaai/comma2k19/resolve/main/Chunk_1.zip?download=true\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/dataset\n",
        "!mv \"Chunk_1.zip?download=true\" Chunk_1.zip\n",
        "!mv Chunk_1.zip /content/dataset"
      ],
      "metadata": {
        "id": "Ps1QT-kgEYua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GGK-mGX76_7"
      },
      "outputs": [],
      "source": [
        "!wget https://huggingface.co/datasets/commaai/comma2k19/resolve/main/Chunk_2.zip?download=true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvTgeC_q75Wu"
      },
      "outputs": [],
      "source": [
        "!wget https://huggingface.co/datasets/commaai/comma2k19/resolve/main/Chunk_3.zip?download=true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35cEY7mNk5U4"
      },
      "outputs": [],
      "source": [
        "!unzip /content/dataset/Chunk_1.zip -d /content/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtJRHKtjAzZg"
      },
      "outputs": [],
      "source": [
        "dataset_type = \"train\"\n",
        "main_dir='/content/dataset/Chunk_1/'\n",
        "hdf5_filename = \"gas_and_brake_train_comma_chunk_1_w_imgs.hdf5\"\n",
        "h_train = h5py.File(hdf5_filename, 'w')\n",
        "hdf5_filename = \"gas_and_brake_val_comma_chunk_1_w_imgs.hdf5\"\n",
        "h_val = h5py.File(hdf5_filename, 'w')\n",
        "hdf5_filename = \"gas_and_brake_test_comma_chunk_1_w_imgs.hdf5\"\n",
        "h_test = h5py.File(hdf5_filename, 'w')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEc4jw_AA6xS",
        "outputId": "63381827-4a00-4224-f218-ce0a2e6fd612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "22it [1:42:27, 279.45s/it]\n"
          ]
        }
      ],
      "source": [
        "for j, drive_sequence_path in tqdm(enumerate(os.listdir(main_dir))):\n",
        "    if '.DS_Store ' in drive_sequence_path or not os.path.isdir(main_dir+\"/\"+drive_sequence_path): continue\n",
        "    min_sequence_paths = os.listdir(main_dir+\"/\"+drive_sequence_path)\n",
        "    if len(min_sequence_paths) < 3: continue\n",
        "    min_sequence_path_test = main_dir+\"/\"+drive_sequence_path+\"/\"+min_sequence_paths[-2]\n",
        "    min_sequence_paths_val = main_dir+\"/\"+drive_sequence_path+\"/\"+min_sequence_paths[-1]\n",
        "    sample = get_sample(min_sequence_path_test)\n",
        "    if sample != None:\n",
        "        save_h5py(f\"{drive_sequence_path}\", sample, h_test)\n",
        "    sample = get_sample(min_sequence_paths_val)\n",
        "\n",
        "    if sample != None:\n",
        "        save_h5py(f\"{drive_sequence_path}\", sample, h_val)\n",
        "    for i, min_sequence in enumerate(min_sequence_paths[:-2]):\n",
        "        if '.DS_Store ' in min_sequence or not os.path.isdir(main_dir+\"/\"+drive_sequence_path+'/'+min_sequence): continue\n",
        "        p = main_dir+\"/\"+drive_sequence_path+\"/\"+min_sequence\n",
        "        sample = get_sample(p)\n",
        "        if sample != None:\n",
        "            save_h5py(f\"{drive_sequence_path}_{min_sequence}\", sample, h_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ArDGyyJJA-k3"
      },
      "outputs": [],
      "source": [
        "h_test.close()\n",
        "h_train.close()\n",
        "h_val.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/gas_and_brake_train_comma_chunk_1_w_imgs.hdf5\")\n",
        "files.download(\"/content/gas_and_brake_val_comma_chunk_1_w_imgs.hdf5\")\n",
        "files.download(\"/content/gas_and_brake_test_comma_chunk_1_w_imgs.hdf5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "cNlbZUpBCo2B",
        "outputId": "51da003a-4d7a-49c8-fd9a-72552acda8c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6d4e1aed-1124-4e99-94ad-02c750deacd3\", \"gas_and_brake_train_comma_chunk_1_w_imgs.hdf5\", 4266749683)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b08571c5-e141-4cbd-a0bb-07f4988f4765\", \"gas_and_brake_val_comma_chunk_1_w_imgs.hdf5\", 720355403)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d02dbd04-b843-4404-b298-a60da2575c06\", \"gas_and_brake_test_comma_chunk_1_w_imgs.hdf5\", 554402583)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean Up Data"
      ],
      "metadata": {
        "id": "4iPhIbWjLjeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from scipy import ndimage\n",
        "import os\n",
        "\n",
        "# 📁 Directory dove si trovano i file chunk_1\n",
        "base_path = \"/content\"  # cambia se lavori in locale\n",
        "dataset_types = ['train', 'val', 'test']\n",
        "\n",
        "for dataset_type in dataset_types:\n",
        "    input_path = os.path.join(base_path, f\"gas_and_brake_{dataset_type}_comma_chunk_1_w_imgs.hfd5\")\n",
        "    output_path = os.path.join(base_path, f\"filtered_chunk1_{dataset_type}.hdf5\")\n",
        "\n",
        "    print(f\"🔄 Processing {dataset_type} from: {input_path}\")\n",
        "\n",
        "    if not os.path.exists(input_path):\n",
        "        print(f\"❌ File not found: {input_path}\")\n",
        "        continue\n",
        "\n",
        "    with h5py.File(input_path, \"r\") as h5_file, h5py.File(output_path, \"w\") as h_out:\n",
        "        keys = list(h5_file.keys())\n",
        "\n",
        "        # Opzionale: escludi chiavi problematiche\n",
        "        # bad_keys = ['37', '53', '55', '58']\n",
        "        # keys = [k for k in keys if k not in bad_keys]\n",
        "\n",
        "        for key in tqdm(keys, desc=f\"Processing {dataset_type}\"):\n",
        "            group_in = h5_file[key]\n",
        "\n",
        "            if 'desired_dist' not in group_in:\n",
        "                continue\n",
        "\n",
        "            desired = np.array(group_in['desired_dist'][()])\n",
        "            filtered = ndimage.median_filter(desired, size=12)\n",
        "\n",
        "            if (filtered == 0).mean() > 0.2:\n",
        "                continue  # scarta campioni poco informativi\n",
        "\n",
        "            group_out = h_out.create_group(key)\n",
        "\n",
        "            for col in group_in.keys():\n",
        "                dt = np.float32 if col != 'image' else int\n",
        "                group_out.create_dataset(\n",
        "                    col,\n",
        "                    data=group_in[col],\n",
        "                    compression='gzip',\n",
        "                    compression_opts=6,\n",
        "                    chunks=True\n",
        "                )\n",
        "\n",
        "    print(f\"✅ Salvato: {output_path}\\n\")"
      ],
      "metadata": {
        "id": "pKDsK_AqQVCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import h5py\n",
        "from scipy import ndimage\n",
        "from tqdm import\n",
        "base_path = \"/content\"  # cambia se lavori in locale\n",
        "dataset_types = ['train', 'val', 'test']"
      ],
      "metadata": {
        "id": "QNCdqoVyLFQr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if dataset_type == \"train\":\n",
        "            data_path = \"/content/gas_and_brake_train_comma_chunk_1_w_imgs.hfd5\"\n",
        "elif dataset_type == \"test\":\n",
        "            data_path = \"/content/gas_and_brake_test_comma_chunk_1_w_imgs.hfd5\"\n",
        "elif dataset_type == \"val\":\n",
        "            data_path = \"/content/gas_and_brake_val_comma_chunk_1_w_imgs.hfd5\"\n",
        "people_seqs = []\n",
        "h5_file = h5py.File(data_path, \"r\")\n",
        "keys = list(h5_file.keys())\n",
        "if dataset_type == \"train\":\n",
        "            h5_file2 = h5py.File(data_path2, \"r\")\n",
        "            keys2 = list(h5_file2.keys())\n",
        "            keys = list(np.array(keys))\n",
        "            keys2 = list(np.array(keys2))\n",
        "            h5_file3 = h5py.File(data_path3, \"r\")\n",
        "            keys3 = list(h5_file3.keys())\n",
        "\n",
        "if dataset_type == \"val\":\n",
        "            keys = np.array(keys)\n",
        "            h5_file2 = h5py.File(data_path2, \"r\")\n",
        "            keys2 = list(h5_file2.keys())\n",
        "            h5_file3 = h5py.File(data_path3, \"r\")\n",
        "            keys3 = list(h5_file3.keys())\n",
        "\n",
        "if dataset_type == \"test\":\n",
        "            keys = np.array(keys)\n",
        "            h5_file2 = h5py.File(data_path2, \"r\")\n",
        "            keys2 = list(h5_file2.keys())\n",
        "            h5_file3 = h5py.File(data_path3, \"r\")\n",
        "            keys3 = list(h5_file3.keys())"
      ],
      "metadata": {
        "id": "cDtYaC24LL4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = h5py.File(f\"/data1/jessica/data/toyota/comma_{dataset_type}_w_desired_filtered.h5py\", 'w')"
      ],
      "metadata": {
        "id": "mV2BBO5fL2-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in tqdm(keys):\n",
        "    data = h5_file[key]\n",
        "    group  = h.create_group(key)\n",
        "    for col in data.keys():\n",
        "        dt = np.float32 if col != 'image' else int#\n",
        "        dataset_name = col #groups are divided by '/'\n",
        "        a = data[col]\n",
        "        group.create_dataset(dataset_name, data = a, compression_opts=6, compression='gzip', chunks=True)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "mT6jr6-fL4c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in tqdm(h.keys()):\n",
        "    data = h[key]\n",
        "    t = np.array((data['desired_dist'][()]))\n",
        "    result = ndimage.median_filter(t, size=12)\n",
        "    print((result == 0).mean())\n",
        "    if not (len(data.keys()) >= 5):\n",
        "        print(key, data.keys())"
      ],
      "metadata": {
        "id": "DNSAJKpjL_ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = h5_file4['99c94dc769b5d96e|2018-05-13--20-53-38_29']\n",
        "data_new = h['99c94dc769b5d96e|2018-05-13--20-53-38_29']"
      ],
      "metadata": {
        "id": "tY6tVK-iMJX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in data.keys():\n",
        "    if col in ['angle', 'brake', 'dist', 'gas']: continue\n",
        "    print(key,col)\n",
        "    dt = np.float32 if col != 'image' else int#\n",
        "    dataset_name = col #groups are divided by '/'\n",
        "    a = data[col]\n",
        "    data_new.create_dataset(dataset_name, data = a, compression_opts=6, compression='gzip')"
      ],
      "metadata": {
        "id": "luq-mxq3MK6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new = h['99c94dc769b5d96e|2018-05-13--20-53-38_29']\n",
        "data_new"
      ],
      "metadata": {
        "id": "IxSXg7BaMODZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in tqdm(keys4):\n",
        "    data = h5_file4[key]\n",
        "    if key != '99c94dc769b5d96e|2018-05-13--20-53-38_29':\n",
        "        continue\n",
        "    group  = h.create_group(key)\n",
        "    for col in data.keys():\n",
        "        if col in ['angle', 'brake', 'dist', 'gas']: continue\n",
        "        print(key,col)\n",
        "        dt = np.float32 if col != 'image' else int#\n",
        "        dataset_name = col #groups are divided by '/'\n",
        "        a = data[col]\n",
        "        group.create_dataset(dataset_name, data = a, compression_opts=6, compression='gzip')"
      ],
      "metadata": {
        "id": "BaurkTyfMPYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h.close()"
      ],
      "metadata": {
        "id": "_Sh3RPznMQ9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nhv6qa3tlhN7",
        "outputId": "a155ffee-8bbb-40d1-8d23-28f139ba4f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,683 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease [24.6 kB]\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,944 kB]\n",
            "Get:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 Packages [77.3 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,363 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,245 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,517 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,934 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,546 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
            "Get:21 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,725 kB]\n",
            "Fetched 30.6 MB in 5s (6,703 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.9).\n",
            "python3.10 set to manually installed.\n",
            "python3.10-dev is already the newest version (3.10.12-1~22.04.9).\n",
            "python3.10-dev set to manually installed.\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 89 not upgraded.\n",
            "Need to get 2,478 kB of archives.\n",
            "After this operation, 2,748 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.5 [1,680 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy/main amd64 python3-setuptools-whl all 68.1.2-2~jammy3 [792 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.9 [5,722 B]\n",
            "Fetched 2,478 kB in 3s (777 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.5_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../python3-setuptools-whl_68.1.2-2~jammy3_all.deb ...\n",
            "Unpacking python3-setuptools-whl (68.1.2-2~jammy3) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.9_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.9) ...\n",
            "Setting up python3-setuptools-whl (68.1.2-2~jammy3) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.9) ...\n",
            "Requirement already satisfied: pip in ./py310env/lib/python3.10/site-packages (22.0.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 22.0.2\n",
            "    Uninstalling pip-22.0.2:\n",
            "      Successfully uninstalled pip-22.0.2\n",
            "Successfully installed pip-25.1.1\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-8ls5bnxi\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-8ls5bnxi\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy (from clip==1.0)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting packaging (from clip==1.0)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting regex (from clip==1.0)\n",
            "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "Collecting tqdm (from clip==1.0)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting torch (from clip==1.0)\n",
            "  Downloading torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchvision (from clip==1.0)\n",
            "  Downloading torchvision-0.22.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting wcwidth (from ftfy->clip==1.0)\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting filelock (from torch->clip==1.0)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch->clip==1.0)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy>=1.13.3 (from torch->clip==1.0)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch->clip==1.0)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch->clip==1.0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch->clip==1.0)\n",
            "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch->clip==1.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch->clip==1.0)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch->clip==1.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch->clip==1.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch->clip==1.0)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.0 (from torch->clip==1.0)\n",
            "  Downloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in ./py310env/lib/python3.10/site-packages (from triton==3.3.0->torch->clip==1.0) (68.1.2)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch->clip==1.0)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch->clip==1.0)\n",
            "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting numpy (from torchvision->clip==1.0)\n",
            "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->clip==1.0)\n",
            "  Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.0-cp310-cp310-manylinux_2_28_x86_64.whl (865.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m134.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m145.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.3.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.4/156.4 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m123.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.0-cp310-cp310-manylinux_2_28_x86_64.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m113.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m133.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369549 sha256=fba62c830d71cedd2fec4668458407ffc1e579caae1b927d1c4ce18193b0a681\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vr54uc8t/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built clip\n",
            "Installing collected packages: wcwidth, nvidia-cusparselt-cu12, mpmath, typing-extensions, triton, tqdm, sympy, regex, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, ftfy, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchvision, clip\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33/33\u001b[0m [clip]\n",
            "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 clip-1.0 filelock-3.18.0 fsspec-2025.3.2 ftfy-6.3.1 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 packaging-25.0 pillow-11.2.1 regex-2024.11.6 sympy-1.14.0 torch-2.7.0 torchvision-0.22.0 tqdm-4.67.1 triton-3.3.0 typing-extensions-4.13.2 wcwidth-0.2.13\n",
            "Collecting h5py==3.8.0\n",
            "  Downloading h5py-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting humanize==4.6.0\n",
            "  Downloading humanize-4.6.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting local_attention==1.8.6\n",
            "  Downloading local_attention-1.8.6-py3-none-any.whl.metadata (684 bytes)\n",
            "Collecting matplotlib==3.7.1\n",
            "  Downloading matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting numba==0.56.4\n",
            "  Downloading numba-0.56.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting numpy==1.23.5\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting opencv_python==4.7.0.72\n",
            "  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting pandas==1.5.3\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting Pillow==9.5.0\n",
            "  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
            "Collecting psutil==5.9.4\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting pytorch_lightning==1.9.4\n",
            "  Downloading pytorch_lightning-1.9.4-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting scikit_learn==1.2.2\n",
            "  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scipy==1.10.1\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "Collecting seaborn==0.12.2\n",
            "  Downloading seaborn-0.12.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting timm==0.9.1\n",
            "  Downloading timm-0.9.1-py3-none-any.whl.metadata (68 kB)\n",
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchvision==0.15.1\n",
            "  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting tqdm==4.65.0\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl.metadata (56 kB)\n",
            "Collecting transformers==4.29.1\n",
            "  Downloading transformers-4.29.1-py3-none-any.whl.metadata (112 kB)\n",
            "Collecting einops>=0.6.0 (from local_attention==1.8.6)\n",
            "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib==3.7.1)\n",
            "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib==3.7.1)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib==3.7.1)\n",
            "  Downloading fonttools-4.58.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (104 kB)\n",
            "Collecting kiwisolver>=1.0.1 (from matplotlib==3.7.1)\n",
            "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in ./py310env/lib/python3.10/site-packages (from matplotlib==3.7.1) (25.0)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib==3.7.1)\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting python-dateutil>=2.7 (from matplotlib==3.7.1)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting llvmlite<0.40,>=0.39.0dev0 (from numba==0.56.4)\n",
            "  Downloading llvmlite-0.39.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: setuptools in ./py310env/lib/python3.10/site-packages (from numba==0.56.4) (68.1.2)\n",
            "Collecting pytz>=2020.1 (from pandas==1.5.3)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: fsspec>2021.06.0 in ./py310env/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch_lightning==1.9.4) (2025.3.2)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning==1.9.4)\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in ./py310env/lib/python3.10/site-packages (from pytorch_lightning==1.9.4) (4.13.2)\n",
            "Collecting lightning-utilities>=0.6.0.post0 (from pytorch_lightning==1.9.4)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting joblib>=1.1.1 (from scikit_learn==1.2.2)\n",
            "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit_learn==1.2.2)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting huggingface-hub (from timm==0.9.1)\n",
            "  Downloading huggingface_hub-0.31.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting safetensors (from timm==0.9.1)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: filelock in ./py310env/lib/python3.10/site-packages (from torch==2.0.0) (3.18.0)\n",
            "Requirement already satisfied: sympy in ./py310env/lib/python3.10/site-packages (from torch==2.0.0) (1.14.0)\n",
            "Requirement already satisfied: networkx in ./py310env/lib/python3.10/site-packages (from torch==2.0.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in ./py310env/lib/python3.10/site-packages (from torch==2.0.0) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting requests (from torchvision==0.15.1)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in ./py310env/lib/python3.10/site-packages (from transformers==4.29.1) (2024.11.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.29.1)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting wheel (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0)\n",
            "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting cmake (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading cmake-4.0.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch_lightning==1.9.4)\n",
            "  Downloading aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.4)\n",
            "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.4)\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.4)\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.4)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.4)\n",
            "  Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.4)\n",
            "  Downloading multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.4)\n",
            "  Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.4)\n",
            "  Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
            "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning==1.9.4)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.7->matplotlib==3.7.1)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./py310env/lib/python3.10/site-packages (from jinja2->torch==2.0.0) (3.0.2)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->torchvision==0.15.1)\n",
            "  Downloading charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->torchvision==0.15.1)\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->torchvision==0.15.1)\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./py310env/lib/python3.10/site-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Downloading h5py-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanize-4.6.0-py3-none-any.whl (109 kB)\n",
            "Downloading local_attention-1.8.6-py3-none-any.whl (8.1 kB)\n",
            "Downloading matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.56.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m162.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m147.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "Downloading pytorch_lightning-1.9.4-py3-none-any.whl (827 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m827.8/827.8 kB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m682.2/682.2 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m131.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "Downloading timm-0.9.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m105.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m132.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.31.2-py3-none-any.whl (484 kB)\n",
            "Downloading llvmlite-0.39.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.6/34.6 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m126.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "Downloading fonttools-4.58.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.11.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading multidict-6.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (219 kB)\n",
            "Downloading yarl-1.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (333 kB)\n",
            "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "Downloading frozenlist-1.6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
            "Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
            "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmake-4.0.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: tokenizers, pytz, lit, wheel, urllib3, tqdm, threadpoolctl, six, safetensors, PyYAML, pyparsing, psutil, propcache, Pillow, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, numpy, multidict, llvmlite, lightning-utilities, kiwisolver, joblib, idna, humanize, frozenlist, fonttools, einops, cycler, cmake, charset-normalizer, certifi, attrs, async-timeout, aiohappyeyeballs, yarl, scipy, requests, python-dateutil, opencv_python, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numba, h5py, contourpy, aiosignal, scikit_learn, pandas, nvidia-cusolver-cu11, nvidia-cudnn-cu11, matplotlib, huggingface-hub, aiohttp, transformers, seaborn, triton, torch, torchvision, torchmetrics, timm, pytorch_lightning, local_attention\n",
            "\u001b[2K  Attempting uninstall: tqdm\n",
            "\u001b[2K    Found existing installation: tqdm 4.67.1\n",
            "\u001b[2K    Uninstalling tqdm-4.67.1:\n",
            "\u001b[2K      Successfully uninstalled tqdm-4.67.1\n",
            "\u001b[2K  Attempting uninstall: Pillow\n",
            "\u001b[2K    Found existing installation: pillow 11.2.1\n",
            "\u001b[2K    Uninstalling pillow-11.2.1:\n",
            "\u001b[2K      Successfully uninstalled pillow-11.2.1\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.2.6\n",
            "\u001b[2K    Uninstalling numpy-2.2.6:\n",
            "\u001b[2K      Successfully uninstalled numpy-2.2.6\n",
            "\u001b[2K  Attempting uninstall: triton\n",
            "\u001b[2K    Found existing installation: triton 3.3.0\n",
            "\u001b[2K    Uninstalling triton-3.3.0:\n",
            "\u001b[2K      Successfully uninstalled triton-3.3.0\n",
            "\u001b[2K  Attempting uninstall: torch\n",
            "\u001b[2K    Found existing installation: torch 2.7.0\n",
            "\u001b[2K    Uninstalling torch-2.7.0:\n",
            "\u001b[2K      Successfully uninstalled torch-2.7.0\n",
            "\u001b[2K  Attempting uninstall: torchvision\n",
            "\u001b[2K    Found existing installation: torchvision 0.22.0\n",
            "\u001b[2K    Uninstalling torchvision-0.22.0:\n",
            "\u001b[2K      Successfully uninstalled torchvision-0.22.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66/66\u001b[0m [local_attention]\n",
            "\u001b[1A\u001b[2KSuccessfully installed Pillow-9.5.0 PyYAML-6.0 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 async-timeout-5.0.1 attrs-25.3.0 certifi-2025.4.26 charset-normalizer-3.4.2 cmake-4.0.2 contourpy-1.3.2 cycler-0.12.1 einops-0.8.1 fonttools-4.58.0 frozenlist-1.6.0 h5py-3.8.0 huggingface-hub-0.31.2 humanize-4.6.0 idna-3.10 joblib-1.5.0 kiwisolver-1.4.8 lightning-utilities-0.14.3 lit-18.1.8 llvmlite-0.39.1 local_attention-1.8.6 matplotlib-3.7.1 multidict-6.4.3 numba-0.56.4 numpy-1.23.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 opencv_python-4.7.0.72 pandas-1.5.3 propcache-0.3.1 psutil-5.9.4 pyparsing-3.2.3 python-dateutil-2.9.0.post0 pytorch_lightning-1.9.4 pytz-2025.2 requests-2.32.3 safetensors-0.5.3 scikit_learn-1.2.2 scipy-1.10.1 seaborn-0.12.2 six-1.17.0 threadpoolctl-3.6.0 timm-0.9.1 tokenizers-0.13.3 torch-2.0.0 torchmetrics-1.7.1 torchvision-0.15.1 tqdm-4.65.0 transformers-4.29.1 triton-2.0.0 urllib3-2.4.0 wheel-0.45.1 yarl-1.20.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.10 python3.10-venv python3.10-dev -y\n",
        "\n",
        "!python3.10 -m venv py310env\n",
        "\n",
        "!py310env/bin/pip install --upgrade pip\n",
        "!py310env/bin/pip install git+https://github.com/openai/CLIP.git\n",
        "\n",
        "!py310env/bin/pip install \\\n",
        "    h5py==3.8.0 \\\n",
        "    humanize==4.6.0 \\\n",
        "    local_attention==1.8.6 \\\n",
        "    matplotlib==3.7.1 \\\n",
        "    numba==0.56.4 \\\n",
        "    numpy==1.23.5 \\\n",
        "    opencv_python==4.7.0.72 \\\n",
        "    pandas==1.5.3 \\\n",
        "    Pillow==9.5.0 \\\n",
        "    psutil==5.9.4 \\\n",
        "    pytorch_lightning==1.9.4 \\\n",
        "    PyYAML==6.0 \\\n",
        "    scikit_learn==1.2.2 \\\n",
        "    scipy==1.10.1 \\\n",
        "    seaborn==0.12.2 \\\n",
        "    timm==0.9.1 \\\n",
        "    torch==2.0.0 \\\n",
        "    torchvision==0.15.1 \\\n",
        "    tqdm==4.65.0 \\\n",
        "    transformers==4.29.1\n",
        "!py310env/bin/pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5bCyVVerNK_",
        "outputId": "8e83c553-3946-4934-a20f-d551dde049cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'concept_gridlock' already exists and is not an empty directory.\n",
            "fatal: destination path 'comma2k19' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Gabriele-Raffaele/concept_gridlock.git\n",
        "!git clone https://github.com/commaai/comma2k19.git\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEf27iz2dS29",
        "outputId": "045bd091-c253-40b6-b9ed-b53a78106f66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'concept_gridlock'\n",
            "/content/concept_gridlock/comma_preprocess\n"
          ]
        }
      ],
      "source": [
        "%cd concept_gridlock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV7BfiPefZvT",
        "outputId": "4af067db-5e7e-440b-d090-2cfb0563d09a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: ../py310env/bin/python: No such file or directory\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xu3NXVhcwIof",
        "outputId": "8fb98e75-8ec7-49d8-fb78-388d6091a155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:24<00:00, 14.6MiB/s]\n",
            "using clip backbone\n",
            "/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_distance_clip_None_1\n",
            "⚠️ Nessuna versione precedente trovata, si procede senza resume.\n",
            "RESUME FROM: None\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name     | Type    | Params\n",
            "-------------------------------------\n",
            "0 | model    | VTN     | 167 M \n",
            "1 | bce_loss | BCELoss | 0     \n",
            "-------------------------------------\n",
            "167 M     Trainable params\n",
            "0         Non-trainable params\n",
            "167 M     Total params\n",
            "668.211   Total estimated model params size (MB)\n",
            "Sanity Checking: 0it [00:00, ?it/s]Traceback (most recent call last):\n",
            "  File \"/content/concept_gridlock/main.py\", line 116, in <module>\n",
            "    trainer.fit(module)\n",
            "  File \"/content/py310env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 608, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/content/py310env/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\", line 38, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/content/py310env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 650, in _fit_impl\n",
            "    self._run(model, ckpt_path=self.ckpt_path)\n",
            "  File \"/content/py310env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1112, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/content/py310env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1191, in _run_stage\n",
            "    self._run_train()\n",
            "  File \"/content/py310env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1204, in _run_train\n",
            "    self._run_sanity_check()\n",
            "  File \"/content/py310env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1269, in _run_sanity_check\n",
            "    val_loop._reload_evaluation_dataloaders()\n",
            "  File \"/content/py310env/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\", line 234, in _reload_evaluation_dataloaders\n",
            "    self.trainer.reset_val_dataloader()\n",
            "  File \"/content/py310env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1649, in reset_val_dataloader\n",
            "    self.num_val_batches, self.val_dataloaders = self._data_connector._reset_eval_dataloader(\n",
            "  File \"/content/py310env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 357, in _reset_eval_dataloader\n",
            "    dataloaders = self._request_dataloader(mode)\n",
            "  File \"/content/py310env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 446, in _request_dataloader\n",
            "    dataloader = source.dataloader()\n",
            "  File \"/content/py310env/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 520, in dataloader\n",
            "    return self.instance.trainer._call_lightning_module_hook(self.name, pl_module=self.instance)\n",
            "  File \"/content/py310env/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\", line 1356, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/content/concept_gridlock/module.py\", line 160, in val_dataloader\n",
            "    return self.get_dataloader(dataset_type=\"val\")\n",
            "  File \"/content/concept_gridlock/module.py\", line 176, in get_dataloader\n",
            "    ds = CommaDataset(dataset_type=dataset_type, multitask=self.multitask if not self.intervention else \"intervention\", ground_truth=self.ground_truth, dataset_path=self.dataset_path, dataset_fraction=self.dataset_fraction)\n",
            "  File \"/content/concept_gridlock/dataloader_comma.py\", line 38, in __init__\n",
            "    self.h5_file = h5py.File(data_path, \"r\")\n",
            "  File \"/content/py310env/lib/python3.10/site-packages/h5py/_hl/files.py\", line 567, in __init__\n",
            "    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)\n",
            "  File \"/content/py310env/lib/python3.10/site-packages/h5py/_hl/files.py\", line 231, in make_fid\n",
            "    fid = h5f.open(name, flags, fapl=fapl)\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5f.pyx\", line 106, in h5py.h5f.open\n",
            "FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = '/data1/jessica/data/toyota//comma_val_w_desired_filtered.h5py', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
          ]
        }
      ],
      "source": [
        "!../py310env/bin/python main.py -task distance -train -gpu_num 0 -dataset comma -backbone clip -bs 4 -ground_truth normal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bA8rEQdI0QE8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP9b/VaeI9WTbg7pq6xI+rD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}