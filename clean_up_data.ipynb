{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import h5py\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm\n",
    "dataset_type = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_type == \"train\":\n",
    "            data_path = \"/data1/jessica/data/toyota/gas_and_brake_train_comma_chunk_1_w_imgs.hfd5\"\n",
    "            data_path2 = \"/data1/jessica/data/toyota/gas_and_brake_train_comma_chunk_2_w_imgs.hfd5\"\n",
    "            data_path3 = \"/data1/jessica/data/toyota/gas_and_brake_train_comma_chunk_3_w_imgs.hfd5\"\n",
    "elif dataset_type == \"test\":\n",
    "            data_path = \"/data1/jessica/data/toyota/gas_and_brake_test_comma_chunk_1_w_imgs.hfd5\"\n",
    "            data_path2 = \"/data1/jessica/data/toyota/gas_and_brake_test_comma_chunk_2_w_imgs.hfd5\"\n",
    "            data_path3 = \"/data1/jessica/data/toyota/gas_and_brake_test_comma_chunk_3_w_imgs.hfd5\"\n",
    "elif dataset_type == \"val\":\n",
    "            data_path = \"/data1/jessica/data/toyota/gas_and_brake_val_comma_chunk_1_w_imgs.hfd5\"\n",
    "            data_path2 = \"/data1/jessica/data/toyota/gas_and_brake_val_comma_chunk_2_w_imgs.hfd5\"\n",
    "            data_path3 = \"/data1/jessica/data/toyota/gas_and_brake_val_comma_chunk_3_w_imgs.hfd5\"\n",
    "people_seqs = []\n",
    "h5_file = h5py.File(data_path, \"r\")\n",
    "keys = list(h5_file.keys())\n",
    "#keys.remove('10')\n",
    "#keys.remove('17')\n",
    "if dataset_type == \"train\":\n",
    "            #keys.remove('37')\n",
    "            #keys.remove('53')\n",
    "            #keys.remove('55')\n",
    "            #keys.remove('58')\n",
    "            h5_file2 = h5py.File(data_path2, \"r\")\n",
    "            keys2 = list(h5_file2.keys())\n",
    "            #good_keys = [0, 1, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 19, 20, 21, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 45, 46, 50, 52, 53]#[0, 1, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 21, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 50, 52, 53]\n",
    "            #gk2 = np.array([55, 56, 57, 60, 62, 64, 65, 66, 67, 68, 69, 70, 72, 73, 76, 77, 78, 81, 82, 84, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106]) - 55# np.array([55, 56, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 78, 81, 82, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106]) -55\n",
    "            keys = list(np.array(keys))#[good_keys])\n",
    "            keys2 = list(np.array(keys2))#[gk2])[:-1]\n",
    "            h5_file3 = h5py.File(data_path3, \"r\")\n",
    "            keys3 = list(h5_file3.keys())\n",
    "            #h5_file4 = h5py.File(data_path4, \"r\")\n",
    "            #keys4 = list(h5_file4.keys())\n",
    "#else:\n",
    "#            keys4 = []\n",
    "\n",
    "if dataset_type == \"val\":\n",
    "            #good_keys = [1, 6, 9, 10, 11, 12, 14, 15]\n",
    "            keys = np.array(keys)#[good_keys]\n",
    "            h5_file2 = h5py.File(data_path2, \"r\")\n",
    "            keys2 = list(h5_file2.keys())\n",
    "            h5_file3 = h5py.File(data_path3, \"r\")\n",
    "            keys3 = list(h5_file3.keys())\n",
    "            \n",
    "if dataset_type == \"test\":\n",
    "            #good_keys = [0, 6, 8, 9, 10, 13]\n",
    "            keys = np.array(keys)#[good_keys]\n",
    "            h5_file2 = h5py.File(data_path2, \"r\")\n",
    "            keys2 = list(h5_file2.keys())#[0:3] + list(h5_file2.keys())[5:]\n",
    "            h5_file3 = h5py.File(data_path3, \"r\")\n",
    "            keys3 = list(h5_file3.keys())#[:-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "/data1/jessica/data/toyota/comma_train_filtered.h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = h5py.File(f\"/data1/jessica/data/toyota/comma_{dataset_type}_w_desired_filtered.h5py\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:52<00:00,  7.52s/it]\n"
     ]
    }
   ],
   "source": [
    "for key in tqdm(keys):\n",
    "    data = h5_file[key]\n",
    "    group  = h.create_group(key)\n",
    "    for col in data.keys():\n",
    "        dt = np.float32 if col != 'image' else int#\n",
    "        dataset_name = col #groups are divided by '/'\n",
    "        a = data[col]\n",
    "        group.create_dataset(dataset_name, data = a, compression_opts=6, compression='gzip', chunks=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:55<00:00,  7.90s/it]\n"
     ]
    }
   ],
   "source": [
    "for key in tqdm(keys2):\n",
    "    data = h5_file2[key]\n",
    "    if key in h5_file2.keys():\n",
    "        key = key + \"_1\"\n",
    "    group  = h.create_group(key)\n",
    "    for col in data.keys():\n",
    "        #print(key,col)\n",
    "        dt = np.float32 if col != 'image' else int#\n",
    "        dataset_name = col #groups are divided by '/'\n",
    "        a = data[col]\n",
    "        group.create_dataset(dataset_name, data = a, compression_opts=6, compression='gzip', chunks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:51<00:00,  7.41s/it]\n"
     ]
    }
   ],
   "source": [
    "for key in tqdm(keys3):\n",
    "    data = h5_file3[key]\n",
    "    group  = h.create_group(key)\n",
    "    for col in data.keys():\n",
    "        dt = np.float32 if col != 'image' else int#\n",
    "        dataset_name = col #groups are divided by '/'\n",
    "        a = data[col]\n",
    "        group.create_dataset(dataset_name, data = a, compression_opts=6, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keys4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mlen\u001b[39m(h\u001b[39m.\u001b[39mkeys()), \u001b[39mlen\u001b[39m(keys)\u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(keys2)\u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(keys3)\u001b[39m+\u001b[39m \u001b[39mlen\u001b[39m(keys4)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keys4' is not defined"
     ]
    }
   ],
   "source": [
    "len(h.keys()), len(keys)+ len(keys2)+ len(keys3)+ len(keys4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 2881.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1875\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.075\n",
      "0.0\n",
      "0.05\n",
      "0.14583333333333334\n",
      "0.0\n",
      "0.03333333333333333\n",
      "0.0\n",
      "0.05\n",
      "0.1\n",
      "0.05416666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for key in tqdm(h.keys()):\n",
    "    data = h[key]\n",
    "    t = np.array((data['desired_dist'][()]))\n",
    "    result = ndimage.median_filter(t, size=12)\n",
    "    print((result == 0).mean())\n",
    "    if not (len(data.keys()) >= 5): \n",
    "        print(key, data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = h5_file4['99c94dc769b5d96e|2018-05-13--20-53-38_29']\n",
    "data_new = h['99c94dc769b5d96e|2018-05-13--20-53-38_29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b0c9d2329ad1606b|2018-11-11--13-08-44_23 image\n",
      "b0c9d2329ad1606b|2018-11-11--13-08-44_23 time\n",
      "b0c9d2329ad1606b|2018-11-11--13-08-44_23 vEgo\n"
     ]
    }
   ],
   "source": [
    "for col in data.keys():\n",
    "    if col in ['angle', 'brake', 'dist', 'gas']: continue\n",
    "    print(key,col)\n",
    "    dt = np.float32 if col != 'image' else int#\n",
    "    dataset_name = col #groups are divided by '/'\n",
    "    a = data[col]\n",
    "    data_new.create_dataset(dataset_name, data = a, compression_opts=6, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 group \"/99c94dc769b5d96e|2018-05-13--20-53-38_29\" (7 members)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new = h['99c94dc769b5d96e|2018-05-13--20-53-38_29']\n",
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tqdm(keys4):\n",
    "    data = h5_file4[key]\n",
    "    if key != '99c94dc769b5d96e|2018-05-13--20-53-38_29': \n",
    "        continue\n",
    "    group  = h.create_group(key)\n",
    "    for col in data.keys():\n",
    "        if col in ['angle', 'brake', 'dist', 'gas']: continue\n",
    "        print(key,col)\n",
    "        dt = np.float32 if col != 'image' else int#\n",
    "        dataset_name = col #groups are divided by '/'\n",
    "        a = data[col]\n",
    "        group.create_dataset(dataset_name, data = a, compression_opts=6, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
