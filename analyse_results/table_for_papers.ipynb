{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jessica/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import torch \n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import pad_collate\n",
    "from dataloader_comma import CommaDataset\n",
    "from dataloader_nuscenes import NUScenesDataset\n",
    "from model import VTN\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "from utils import * \n",
    "import re\n",
    "gpu_num = 1\n",
    "multitask = 'distance'\n",
    "backbone = 'none'\n",
    "concept_features = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "commda_ds = CommaDataset(dataset_type=\"test\",\n",
    "        multitask=\"distance\",\n",
    "        ground_truth=\"normal\", dataset_path='/data1/jessica/data/toyota/')\n",
    "nuscenes_ds = NUScenesDataset(dataset_type=\"test\",\n",
    "        multitask=\"distance\",\n",
    "        ground_truth=\"normal\", dataset_path='/data1/jessica/data/toyota/' )\n",
    "dataloader_comma = DataLoader(commda_ds, batch_size=1, shuffle=False, num_workers=0, collate_fn=pad_collate)\n",
    "dataloader_nuscenes = DataLoader(nuscenes_ds, batch_size=1, shuffle=False, num_workers=0, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regular_ckpt_from_lightning_checkpoint(state_dict):\n",
    "    for key in list(state_dict.keys()):\n",
    "        oldkey = key\n",
    "        if oldkey[0:6] == 'model.':\n",
    "            key = oldkey[6:]\n",
    "            state_dict[key] = state_dict.pop(oldkey)\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using concept features\n"
     ]
    }
   ],
   "source": [
    "model = VTN(multitask=multitask, backbone=backbone, concept_features=concept_features, device = f\"cuda:{gpu_num}\", return_concepts=True)\n",
    "checkpoint_path = '/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_distance_none/lightning_logs/version_0/checkpoints//epoch=50-step=3162.ckpt'\n",
    "ckpt = torch.load(checkpoint_path, map_location=f'cuda:{gpu_num}')\n",
    "state_dict = ckpt['state_dict']\n",
    "state_dict = get_regular_ckpt_from_lightning_checkpoint(state_dict)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "model = model.to(f'cuda:{gpu_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 194.00 MiB (GPU 1; 23.69 GiB total capacity; 12.37 GiB already allocated; 22.62 MiB free; 12.85 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/jessica/personalized_driving_toyota/analyse_results/table_for_papers.ipynb Cell 5\u001b[0m in \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeepz.ucsd.edu/home/jessica/personalized_driving_toyota/analyse_results/table_for_papers.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m distance \u001b[39m=\u001b[39m distance[:, \u001b[39m0\u001b[39m:\u001b[39m30\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda:\u001b[39m\u001b[39m{\u001b[39;00mgpu_num\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeepz.ucsd.edu/home/jessica/personalized_driving_toyota/analyse_results/table_for_papers.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m vego \u001b[39m=\u001b[39m vego[:, \u001b[39m0\u001b[39m:\u001b[39m30\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcuda:\u001b[39m\u001b[39m{\u001b[39;00mgpu_num\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bdeepz.ucsd.edu/home/jessica/personalized_driving_toyota/analyse_results/table_for_papers.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m (logits, attns), concepts \u001b[39m=\u001b[39m model(img, angle, distance, vego)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bdeepz.ucsd.edu/home/jessica/personalized_driving_toyota/analyse_results/table_for_papers.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m s \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mshape\u001b[39m#[batch_size, seq_len, h,w,c]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bdeepz.ucsd.edu/home/jessica/personalized_driving_toyota/analyse_results/table_for_papers.ipynb#X12sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m angle \u001b[39m=\u001b[39m angle\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/personalized_driving_toyota/analyse_results/../model.py:160\u001b[0m, in \u001b[0;36mVTN.forward\u001b[0;34m(self, img, angle, distance, vego)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconcept_features:\n\u001b[1;32m    159\u001b[0m     s \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mshape\u001b[39m#[batch_size, seq_len, h,w,c]\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     logits_per_image, logits_per_text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclip_model(img\u001b[39m.\u001b[39;49mreshape((img\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]\u001b[39m*\u001b[39;49mimg\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], img\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m], img\u001b[39m.\u001b[39;49mshape[\u001b[39m3\u001b[39;49m], img\u001b[39m.\u001b[39;49mshape[\u001b[39m4\u001b[39;49m])), scenarios_tokens\u001b[39m.\u001b[39;49mto(x\u001b[39m.\u001b[39;49mdevice))\n\u001b[1;32m    161\u001b[0m     probs \u001b[39m=\u001b[39m logits_per_image\u001b[39m.\u001b[39msoftmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    162\u001b[0m     probs \u001b[39m=\u001b[39m logits_per_image\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mreshape((\u001b[39mint\u001b[39m(img\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), \u001b[39mint\u001b[39m(logits_per_image\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\u001b[39m/\u001b[39mimg\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/clip/model.py:360\u001b[0m, in \u001b[0;36mCLIP.forward\u001b[0;34m(self, image, text)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, image, text):\n\u001b[1;32m    359\u001b[0m     image_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_image(image)\n\u001b[0;32m--> 360\u001b[0m     text_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode_text(text)\n\u001b[1;32m    362\u001b[0m     \u001b[39m# normalized features\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     image_features \u001b[39m=\u001b[39m image_features \u001b[39m/\u001b[39m image_features\u001b[39m.\u001b[39mnorm(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/clip/model.py:348\u001b[0m, in \u001b[0;36mCLIP.encode_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    346\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpositional_embedding\u001b[39m.\u001b[39mtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    347\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# NLD -> LND\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(x)\n\u001b[1;32m    349\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)  \u001b[39m# LND -> NLD\u001b[39;00m\n\u001b[1;32m    350\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_final(x)\u001b[39m.\u001b[39mtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/clip/model.py:203\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 203\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mresblocks(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/clip/model.py:191\u001b[0m, in \u001b[0;36mResidualAttentionBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m    190\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattention(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln_1(x))\n\u001b[0;32m--> 191\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmlp(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln_2(x))\n\u001b[1;32m    192\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/clip/model.py:168\u001b[0m, in \u001b[0;36mQuickGELU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 168\u001b[0m     \u001b[39mreturn\u001b[39;00m x \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39msigmoid(\u001b[39m1.702\u001b[39;49m \u001b[39m*\u001b[39;49m x)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 194.00 MiB (GPU 1; 23.69 GiB total capacity; 12.37 GiB already allocated; 22.62 MiB free; 12.85 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for batch in dataloader_comma:\n",
    "    _, image_array, vego, angle, distance, m_lens, i_lens, s_lens, a_lens, d_lens = batch\n",
    "    img = image_array[:, 0:30]\n",
    "    img = img.to(f'cuda:{gpu_num}')\n",
    "    angle = angle[:, 0:30].to(f'cuda:{gpu_num}')\n",
    "    distance = distance[:, 0:30].to(f'cuda:{gpu_num}')\n",
    "    vego = vego[:, 0:30].to(f'cuda:{gpu_num}')\n",
    "    (logits, attns), concepts = model(img, angle, distance, vego)\n",
    "    s = img.shape#[batch_size, seq_len, h,w,c]\n",
    "    angle = angle.to(\"cpu\")\n",
    "    distance = distance.to(\"cpu\")\n",
    "    vego = vego.to(\"cpu\")\n",
    "    logits = logits.detach().cpu().to(\"cpu\")\n",
    "    attns = attns.detach().cpu().to(\"cpu\")\n",
    "    concepts = concepts.detach().cpu().to(\"cpu\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 69, 643]),\n",
       " torch.Size([1, 69, 1]),\n",
       " torch.Size([1, 1, 69, 10]),\n",
       " torch.Size([1, 1, 69, 10]),\n",
       " torch.Size([1, 1, 69, 10]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts.shape, logits.shape, attns[0][:,:,0:concepts.shape[1]].shape, attns[1][:,:,0:concepts.shape[1]].shape , attns[2][:,:,0:concepts.shape[1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 80, 10])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attns[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image_array[:, 0:5, :, :].to(f'cuda:{gpu_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_tokens = scenarios_tokens.to(f'cuda:{gpu_num}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_per_image, logits_per_text = clip_model(img.reshape((img.shape[0]*img.shape[1], img.shape[2], img.shape[3], img.shape[4])), scenarios_tokens)\n",
    "probs = logits_per_image.softmax(dim=-1)\n",
    "probs = logits_per_image.detach().reshape((int(img.shape[0]), int(logits_per_image.shape[0]/img.shape[0]), -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = attns[0][:,:,0:concepts.shape[1]].detach()\n",
    "seq_len = att.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(signal, window_size):\n",
    "    window = np.ones(window_size) / window_size\n",
    "    smoothed_signal = np.convolve(signal, window, mode='same')\n",
    "    return smoothed_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_aligned_attention(attention):\n",
    "    attention = attention[:, 1:-1]\n",
    "    sequence_length = seq_len\n",
    "    window_size = 8\n",
    "    overlap = 4\n",
    "    global_attended_token = 1\n",
    "    padding_tokens = 8\n",
    "    # Calculate the number of chunks\n",
    "    number_of_chunks = np.ceil((sequence_length - window_size + overlap + 1) / (window_size - overlap)).astype(int)\n",
    "\n",
    "    # Create an empty alignment array\n",
    "    alignment_array = np.zeros((sequence_length + 2 * window_size , sequence_length + 2 * window_size), dtype=float)\n",
    "\n",
    "    # Iterate over each chunk and extract attended token index\n",
    "    for chunk_idx in range(number_of_chunks):\n",
    "        # Calculate the start and end indices of the chunk\n",
    "        start_index = chunk_idx * (window_size - overlap)\n",
    "        end_index = start_index + window_size\n",
    "        alignment_array[chunk_idx, start_index:end_index] = attention[chunk_idx]\n",
    "    return alignment_array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "atten = att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 85)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_array = get_aligned_attention(atten.squeeze().cpu())\n",
    "speed_graph = alignment_array.sum(axis=0)[8:-8]\n",
    "speed_graph = moving_average(speed_graph, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "/tmp/ipykernel_1135507/2842296409.py:3: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8))\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assuming you have a speed graph as a 1D array\n",
    "for i, image in enumerate(image_array[0]): \n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 8))\n",
    "\n",
    "    # Assuming you have an image frame\n",
    "    image_frame = image.permute(1,2,0)\n",
    "\n",
    "    # Display the image frame\n",
    "    ax1.imshow(image_frame)\n",
    "    ax1.set_title(\"Image Frame\")\n",
    "\n",
    "    # Generate x-axis values for the speed graph\n",
    "    x = np.arange(len(speed_graph))\n",
    "\n",
    "    # Plot the speed graph\n",
    "    ax2.plot(x, speed_graph)\n",
    "    ax2.set_title(\"Speed Graph\")\n",
    "\n",
    "    # Choose a specific time and corresponding speed value to display\n",
    "    time_step = i\n",
    "    speed_value = speed_graph[time_step]\n",
    "\n",
    "    # Add text annotation to the plot at the specified time step\n",
    "    ax2.plot(time_step, speed_value, marker='o', markersize=10, color='r')\n",
    "\n",
    "    # Adjust the plot layout if necessary\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.savefig(f\"/home/jessica/personalized_driving_toyota/result_images/attention/{i}.png\")\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(filename):\n",
    "        match = re.search(r'\\d+', filename)\n",
    "        return int(match.group()) if match else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the directory containing the images\n",
    "image_directory = '/home/jessica/personalized_driving_toyota/result_images/attention'\n",
    "\n",
    "# Set the output GIF file path\n",
    "output_gif_path = '/home/jessica/personalized_driving_toyota/result_images/attention.gif'\n",
    "\n",
    "# Set the duration (in milliseconds) for each frame in the GIF\n",
    "frame_duration = 800\n",
    "\n",
    "# Get a sorted list of image files in the directory\n",
    "image_files = sorted(glob.glob(f'{image_directory}/*.png'), key=extract_number)  # Adjust the file extension if necessary\n",
    "\n",
    "# Create a list to store the frames of the GIF\n",
    "frames = []\n",
    "\n",
    "# Iterate over each image file\n",
    "for image_file in image_files:\n",
    "    # Open the image file\n",
    "    image = Image.open(image_file)\n",
    "\n",
    "    # Add the image to the list of frames\n",
    "    frames.append(image)\n",
    "\n",
    "# Save the frames as a GIF\n",
    "frames[0].save(output_gif_path, format='GIF', append_images=frames[1:], save_all=True,\n",
    "               duration=frame_duration, loop=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_weights = att\n",
    "normalized_weights = attention_weights#np.array(attention_weights) / np.sum(attention_weights)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "heatmap = ax.pcolormesh(alignment_array[0:70, :], cmap='hot')\n",
    "ax.set_aspect('equal')\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(heatmap)\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('Sequence Position')\n",
    "ax.set_ylabel('Window Size')\n",
    "ax.set_title('Longformer Sliding Chunk Attention (Attention Head 1)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(input, target, mask, reduction=\"mean\"):\n",
    "        out = (input[~mask]-target[~mask])**2\n",
    "        return out.mean() if reduction == \"mean\" else out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version_0 ['version_0']\n",
      "version_0 ['version_0']\n",
      "version_5 ['version_4', 'version_5']\n",
      "version_2 ['version_0', 'version_2', 'version_1']\n",
      "version_4 ['version_4', 'version_3']\n",
      "version_0 ['version_0']\n",
      "version_0 ['version_0']\n",
      "version_7 ['version_4', 'version_3', 'version_6', 'version_7', 'version_2', 'version_1', 'version_5']\n",
      "version_2 ['version_0', 'version_2', 'version_1']\n",
      "version_4 ['version_4', 'version_3', 'version_0', 'version_2']\n",
      "version_5 ['version_4', 'version_3', 'version_2', 'version_5']\n",
      "version_6 ['version_4', 'version_3', 'version_6', 'version_2', 'version_1', 'version_5']\n",
      "version_0 ['version_0']\n",
      "version_5 ['version_4', 'version_5']\n",
      "version_2 ['version_2', 'version_1']\n",
      "version_0 ['version_0']\n",
      "version_0 ['version_0']\n",
      "version_1 ['version_0', 'version_1']\n",
      "version_7 ['version_4', 'version_3', 'version_6', 'version_0', 'version_7', 'version_1', 'version_5']\n",
      "version_0 ['version_0']\n",
      "version_8 ['version_7', 'version_8']\n",
      "version_1 ['version_1']\n",
      "version_4 ['version_4']\n",
      "version_2 ['version_2']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p = '/data1/jessica/data/toyota/ckpts_final/'\n",
    "\n",
    "experiments = os.listdir(p)\n",
    "res = {}\n",
    "res_ckpt = {}\n",
    "for elem in experiments:\n",
    "    path = p + elem + \"/lightning_logs/\" \n",
    "    versions =[ elem[-1 ]for elem in os.listdir(path)]\n",
    "    versions = sorted(versions)\n",
    "    version = f\"version_{versions[-1]}\"\n",
    "    print(version, os.listdir(path))\n",
    "    checkpoint_path = path + version + \"/checkpoints/\"\n",
    "    if \"checkpoints\" not in os.listdir(path + version): continue\n",
    "    files = os.listdir(checkpoint_path)\n",
    "\n",
    "    task = []\n",
    "    ckpt = []\n",
    "    for filename in files: \n",
    "        if filename.endswith(\".csv\"):\n",
    "            df = pd.read_csv(checkpoint_path + filename)\n",
    "            df.columns = ['preds', 'targets']\n",
    "            m = (df['targets'] > 50).astype(bool) | (df['targets'] == 0).astype(bool) \n",
    "            \n",
    "            loss3 = torch.sqrt(mse_loss(torch.tensor(df['preds']),  torch.tensor(df['targets']), torch.tensor(m)))\n",
    "            task.append(loss3.item())\n",
    "        if filename.endswith(\".ckpt\"):\n",
    "            ckpt.append(checkpoint_path + '/' + filename)\n",
    "    res[elem] = task\n",
    "    res_ckpt[elem] = ckpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ckpts_final_comma_distance_resnet': [4.665587373198741],\n",
       " 'ckpts_final_comma_multitask_none': [3.3693716510452907, 4.579165410378686],\n",
       " 'ckpts_final_nuscenes_multitask_resnet': [],\n",
       " 'ckpts_final_comma_multitask_resnet': [4.987273033355811, 2.832363118532193],\n",
       " 'ckpts_final_comma_angle_resnet': [3.1649969769178874],\n",
       " 'ckpts_final_nuscenes_multitask_vit': [],\n",
       " 'ckpts_final_nuscenes_multitask_clip': [],\n",
       " 'ckpts_final_nuscenes_angle_none': [],\n",
       " 'ckpts_final_comma_distance_none': [3.3851383559744126],\n",
       " 'ckpts_final_nuscenes_angle_clip': [],\n",
       " 'ckpts_final_nuscenes_distance_clip': [],\n",
       " 'ckpts_final_comma_multitask_vit': [4.923400746465994, 2.9565217244374127],\n",
       " 'ckpts_final_comma_multitask_clip': [],\n",
       " 'ckpts_final_nuscenes_distance_none': [],\n",
       " 'ckpts_final_comma_angle_none': [5.155869130660418],\n",
       " 'ckpts_final_nuscenes_distance_resnet': [28.18212454012493],\n",
       " 'ckpts_final_comma_angle_clip': [],\n",
       " 'ckpts_final_comma_distance_vit': [5.023062603070098]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ckpts_final_comma_distance_resnet': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_distance_resnet/lightning_logs/version_0/checkpoints//epoch=30-step=3844.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_distance_resnet/lightning_logs/version_0/checkpoints//epoch=16-step=2108.ckpt'],\n",
       " 'ckpts_final_comma_multitask_none': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_multitask_none/lightning_logs/version_0/checkpoints//epoch=66-step=4154.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_multitask_none/lightning_logs/version_0/checkpoints//epoch=72-step=4526.ckpt'],\n",
       " 'ckpts_final_nuscenes_angle_vit': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_angle_vit/lightning_logs/version_4/checkpoints//epoch=169-step=23630.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_angle_vit/lightning_logs/version_4/checkpoints//epoch=168-step=23491.ckpt'],\n",
       " 'ckpts_final_nuscenes_multitask_resnet': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_multitask_resnet/lightning_logs/version_3/checkpoints//epoch=169-step=23630.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_multitask_resnet/lightning_logs/version_3/checkpoints//epoch=170-step=23769.ckpt'],\n",
       " 'ckpts_final_comma_multitask_resnet': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_multitask_resnet/lightning_logs/version_0/checkpoints//epoch=87-step=10912.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_multitask_resnet/lightning_logs/version_0/checkpoints//epoch=64-step=8060.ckpt'],\n",
       " 'ckpts_final_comma_angle_resnet': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_angle_resnet/lightning_logs/version_0/checkpoints//epoch=29-step=3720.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_angle_resnet/lightning_logs/version_0/checkpoints//epoch=25-step=3224.ckpt'],\n",
       " 'ckpts_final_nuscenes_distance_vit': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_distance_vit/lightning_logs/version_2/checkpoints//epoch=56-step=7923.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_distance_vit/lightning_logs/version_2/checkpoints//epoch=62-step=8757.ckpt'],\n",
       " 'ckpts_final_nuscenes_multitask_clip': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_multitask_clip/lightning_logs/version_4/checkpoints//epoch=11-step=1668.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_multitask_clip/lightning_logs/version_4/checkpoints//epoch=12-step=1807.ckpt'],\n",
       " 'ckpts_final_nuscenes_angle_none': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_angle_none/lightning_logs/version_1/checkpoints//epoch=189-step=26410.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_angle_none/lightning_logs/version_1/checkpoints//epoch=180-step=25159.ckpt'],\n",
       " 'ckpts_final_comma_distance_none': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_distance_none/lightning_logs/version_0/checkpoints//epoch=36-step=2294.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_distance_none/lightning_logs/version_0/checkpoints//epoch=50-step=3162.ckpt'],\n",
       " 'ckpts_final_nuscenes_angle_clip': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_angle_clip/lightning_logs/version_4/checkpoints//epoch=192-step=26827.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_angle_clip/lightning_logs/version_4/checkpoints//epoch=198-step=27661.ckpt'],\n",
       " 'ckpts_final_nuscenes_distance_clip': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_distance_clip/lightning_logs/version_1/checkpoints//epoch=116-step=16263.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_distance_clip/lightning_logs/version_1/checkpoints//epoch=101-step=14178.ckpt'],\n",
       " 'ckpts_final_comma_multitask_vit': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_multitask_vit/lightning_logs/version_0/checkpoints//epoch=165-step=41002.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_multitask_vit/lightning_logs/version_0/checkpoints//epoch=166-step=41249.ckpt'],\n",
       " 'ckpts_final_comma_multitask_clip': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_multitask_clip/lightning_logs/version_0/checkpoints//epoch=103-step=25688.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_multitask_clip/lightning_logs/version_0/checkpoints//epoch=21-step=5434.ckpt'],\n",
       " 'ckpts_final_nuscenes_distance_none': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_distance_none/lightning_logs/version_3/checkpoints//epoch=16-step=1190.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_distance_none/lightning_logs/version_3/checkpoints//epoch=17-step=1260.ckpt'],\n",
       " 'ckpts_final_comma_angle_none': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_angle_none/lightning_logs/version_0/checkpoints//epoch=1-step=124.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_angle_none/lightning_logs/version_0/checkpoints//epoch=2-step=186.ckpt'],\n",
       " 'ckpts_final_nuscenes_distance_resnet': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_distance_resnet/lightning_logs/version_1/checkpoints//epoch=137-step=19182.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_nuscenes_distance_resnet/lightning_logs/version_1/checkpoints//epoch=183-step=25576.ckpt'],\n",
       " 'ckpts_final_comma_angle_clip': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_angle_clip/lightning_logs/version_4/checkpoints//epoch=63-step=7936.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_angle_clip/lightning_logs/version_4/checkpoints//epoch=65-step=8184.ckpt'],\n",
       " 'ckpts_final_comma_distance_vit': ['/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_distance_vit/lightning_logs/version_2/checkpoints//epoch=10-step=2717.ckpt',\n",
       "  '/data1/jessica/data/toyota/ckpts_final/ckpts_final_comma_distance_vit/lightning_logs/version_2/checkpoints//epoch=3-step=988.ckpt']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
